{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from pathlib import Path\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mallet_path = '../mallet-2.0.8/bin/mallet' # update this path\n",
    "\n",
    "num_topics = 20\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "#     contents = pd.Series(texts)\n",
    "#     sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "def get_preprocessed_text(bookpath):\n",
    "    preprocessed_sents = []\n",
    "    preprocessed_sents_per_chapter = {}\n",
    "    with open(bookpath) as book_json:\n",
    "        chapter_par_dict = json.load(book_json)\n",
    "        \n",
    "        # for chapter, paragraphs in book\n",
    "        for chapter, pars in chapter_par_dict.items():\n",
    "            preprocessed_sents_per_chapter[chapter] = []\n",
    "            \n",
    "            # For actual paragraph in chapter\n",
    "            for par in pars:\n",
    "                sents = nltk.sent_tokenize(par)\n",
    "                for sentence in sents:\n",
    "                    sent = re.sub(r'\\s+', ' ', sentence)  # remove newline chars\n",
    "                    sent = re.sub(r'\\\"', '', sent)  # remove single quotes\n",
    "                    sent = re.sub(r\"\\'\", '', sent)  # remove single quotes\n",
    "                    sent = re.sub(r\"\\*\", '', sent)  # remove * in text\n",
    "                    # Remove words that are smaller than given threshold (like J K R O W L I N G)\n",
    "                    preprocessed_sents.append(sent)\n",
    "                    preprocessed_sents_per_chapter[chapter].append(sent)\n",
    "    return preprocessed_sents, preprocessed_sents_per_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def remove_shortwords(texts, wordlen_thresh=2):\n",
    "    return [[word for word in doc if len(word.strip()) >= wordlen_thresh] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts, bigram_mod):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(nlp, texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PROPN']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Start Book book_2_coref.json\n",
      "==> Start Book book_7_coref.json\n",
      "==> Start Book book_3_coref.json\n",
      "==> Start Book book_6_coref.json\n",
      "==> Start Book book_4_coref.json\n",
      "==> Start Book book_5_coref.json\n",
      "==> Start Book book_1_coref.json\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bookPaths = Path('../data/books_json')\n",
    "books = [book for book in bookPaths.iterdir() if 'book_' in book.name]\n",
    "\n",
    "with open('../data/chapters/chapter_numbers.json') as chapter_numerated:\n",
    "    chapter_numbers = json.load(chapter_numerated)\n",
    "\n",
    "for book in books:\n",
    "    print(f'==> Start Book {book.name}')\n",
    "    book_compl, book_chapters = get_preprocessed_text(str(book))\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(book_chapters.values(), min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[book_chapters.values()], threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    data_lemmatized = lemmatization(nlp, book_chapters.values())\n",
    "\n",
    "    # Remove Stop Words\n",
    "    data_words_nostops = remove_stopwords(data_lemmatized)\n",
    "    data_wo_shortwords = remove_shortwords(data_words_nostops)\n",
    "    #print(data_wo_shortwords)\n",
    "    # Form Bigrams\n",
    "    data_words_bigrams = make_bigrams(data_wo_shortwords, bigram_mod)\n",
    "    #print(data_words_bigrams)\n",
    "    # Do lemmatization keeping only noun, adj, vb, adv\n",
    "    #data_lemmatized = lemmatization(nlp, data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "    \n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_words_bigrams)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = data_wo_shortwords\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    \n",
    "#     # Continue from 16 on LDA website\n",
    "    ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "    \n",
    "    # Show Topics\n",
    " #   print(ldamallet.show_topics(formatted=True))\n",
    "    df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=texts)\n",
    "\n",
    "    # Format\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "#    print(df_dominant_topic.head())\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords']\n",
    "\n",
    "    # Show\n",
    "    df_dominant_topic.to_csv(f'../data/topics/{book.name[:-5]}_gensim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Start Book book_2_coref.json\n",
      " ---> Num Topics = 6  has Coherence Value of 0.2423\n",
      " ---> Num Topics = 8  has Coherence Value of 0.2624\n",
      " ---> Num Topics = 10  has Coherence Value of 0.2714\n",
      " ---> Num Topics = 12  has Coherence Value of 0.2714\n",
      " ---> Num Topics = 14  has Coherence Value of 0.3073\n",
      " ---> Num Topics = 16  has Coherence Value of 0.2852\n",
      " ---> Num Topics = 18  has Coherence Value of 0.3038\n",
      " ---> Num Topics = 20  has Coherence Value of 0.2844\n",
      " ---> Num Topics = 22  has Coherence Value of 0.2813\n",
      " ---> Num Topics = 24  has Coherence Value of 0.2892\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Start Book book_7_coref.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dad0da682c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-728b733e2a42>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(dictionary, corpus, texts, limit, start, step)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcoherencemodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COMMAND: %s %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1910\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1911\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bookPaths = Path('../data/books_json')\n",
    "books = [book for book in bookPaths.iterdir() if 'book_' in book.name]\n",
    "\n",
    "with open('../data/chapters/chapter_numbers.json') as chapter_numerated:\n",
    "    chapter_numbers = json.load(chapter_numerated)\n",
    "\n",
    "for book in books:\n",
    "    print(f'==> Start Book {book.name}')\n",
    "    book_compl, book_chapters = get_preprocessed_text(str(book))\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(book_chapters.values(), min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    trigram = gensim.models.Phrases(bigram[book_chapters.values()], threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    data_lemmatized = lemmatization(nlp, book_chapters.values())\n",
    "\n",
    "    # Remove Stop Words\n",
    "    data_words_nostops = remove_stopwords(data_lemmatized)\n",
    "    data_wo_shortwords = remove_shortwords(data_words_nostops)\n",
    "    # Form Bigrams\n",
    "    data_words_bigrams = make_bigrams(data_wo_shortwords, bigram_mod)\n",
    "    #print(data_words_bigrams)\n",
    "    # Do lemmatization keeping only noun, adj, vb, adv\n",
    "    #data_lemmatized = lemmatization(nlp, data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "    \n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_words_bigrams)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = data_words_bigrams\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    \n",
    "    start = 6\n",
    "    limit = 26\n",
    "    step = 2\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=start, limit=limit, step=step)\n",
    "    x = range(start, limit, step)\n",
    "    for m, cv in zip(x, coherence_values):\n",
    "        print(\" ---> Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()\n",
    "#     # Continue from 16 on LDA website\n",
    "#     ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "    \n",
    "#     # Show Topics\n",
    "#  #   print(ldamallet.show_topics(formatted=True))\n",
    "#     df_topic_sents_keywords = format_topics_sentences(ldamodel=ldamallet, corpus=corpus, texts=texts)\n",
    "\n",
    "#     # Format\n",
    "#     df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "# #    print(df_dominant_topic.head())\n",
    "#     df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords']\n",
    "\n",
    "#     # Show\n",
    "#     df_dominant_topic.to_csv(f'../data/topics/{book.name[:-5]}_gensim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Can take a long time to run.\n",
    "\n",
    "\n",
    "\n",
    "    # Show graph\n",
    "    limit=40; start=2; step=6;\n",
    "    x = range(start, limit, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.2134\n",
      "Num Topics = 8  has Coherence Value of 0.3351\n",
      "Num Topics = 14  has Coherence Value of 0.3502\n",
      "Num Topics = 20  has Coherence Value of 0.3699\n",
      "Num Topics = 26  has Coherence Value of 0.3684\n",
      "Num Topics = 32  has Coherence Value of 0.3548\n",
      "Num Topics = 38  has Coherence Value of 0.3776\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
